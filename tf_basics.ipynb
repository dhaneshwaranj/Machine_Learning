{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.10958119,  0.3157427 , -0.1763657 ,  0.53088075, -0.07045592,\n",
       "        -0.50794697,  0.01168521,  0.90586346,  0.7809997 , -0.16067344]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06968443, 0.10662316, 0.06518259, 0.13221623, 0.07246488,\n",
       "        0.04678727, 0.07866853, 0.19237018, 0.16978921, 0.06621352]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 16s 264us/sample - loss: 0.2941 - accuracy: 0.9147\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 146us/sample - loss: 0.1418 - accuracy: 0.9578\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.1074 - accuracy: 0.9677\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0882 - accuracy: 0.9727\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0744 - accuracy: 0.9763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25099952da0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.0809 - accuracy: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08093898753351532, 0.9748]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[5.78673891e-08, 2.40395237e-09, 9.89058753e-06, 1.40575139e-04,\n",
       "        2.01616162e-13, 4.58505340e-08, 2.57565865e-12, 9.99849081e-01,\n",
       "        9.74144569e-08, 2.16850779e-07],\n",
       "       [3.23151794e-09, 8.45678587e-05, 9.99879956e-01, 3.20618710e-05,\n",
       "        4.86982700e-17, 4.18066293e-07, 1.40831204e-08, 2.15543416e-11,\n",
       "        2.82077326e-06, 7.06521235e-15],\n",
       "       [2.72883483e-07, 9.96994495e-01, 4.97910427e-04, 3.30595867e-05,\n",
       "        3.79852349e-06, 1.57856975e-05, 2.08416131e-05, 1.60580222e-03,\n",
       "        8.27311829e-04, 6.74337002e-07],\n",
       "       [9.99841094e-01, 3.02971372e-08, 2.31872491e-05, 3.32527247e-06,\n",
       "        3.68563349e-08, 9.14662742e-05, 1.62024771e-05, 2.33025676e-05,\n",
       "        7.63386154e-08, 1.30666137e-06],\n",
       "       [4.24074915e-06, 2.28379324e-08, 8.95185622e-06, 3.66280410e-08,\n",
       "        9.95387256e-01, 1.78853327e-06, 6.50169204e-06, 5.48198586e-04,\n",
       "        2.85968072e-05, 4.01437050e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
